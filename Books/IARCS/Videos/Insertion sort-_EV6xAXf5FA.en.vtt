WEBVTT
Kind: captions
Language: en

00:00:00.890 --> 00:00:05.430
So, let us continue with our discussion of
sorting, and look at another simple sorting

00:00:05.430 --> 00:00:06.430
algorithm.

00:00:06.430 --> 00:00:12.010
So, as we said before that are many more motivations
for sorting; starting from searching, to removing

00:00:12.010 --> 00:00:16.129
duplicates, to computing some statistical
properties, such as frequency tables, and

00:00:16.129 --> 00:00:17.890
so on.

00:00:17.890 --> 00:00:23.390
And the example that we have in hand, is one
way we are asked to sort a bunch of exam papers

00:00:23.390 --> 00:00:25.800
in descending order of marks.

00:00:25.800 --> 00:00:32.830
So, second strategy to sort this bunch of
exam papers would be the following. So, you

00:00:32.830 --> 00:00:38.990
take the top most paper in this stack that
you have, and create a new stack with that.

00:00:38.990 --> 00:00:43.190
Now you take the second paper and compare
it to the first paper. If the mark is bigger,

00:00:43.190 --> 00:00:47.870
you put it above, because you want it in descending
order. If the mark is smaller, you put it

00:00:47.870 --> 00:00:54.739
below. So, after this step, you have two stacks
of papers in descending order. Now a stack

00:00:54.739 --> 00:00:59.780
of two papers rather. And now you take the
third paper, and now you see where it fits

00:00:59.780 --> 00:01:04.350
with respect to the first two; either it goes
all the way to the bottom or it goes between

00:01:04.350 --> 00:01:09.220
the two or it goes all the way on top. In
this way at each point you pick up the top

00:01:09.220 --> 00:01:14.049
most paper in the unsorted stack, and you
inserted it into its correct position, in

00:01:14.049 --> 00:01:17.160
the sorted stack that you are building up.

00:01:17.160 --> 00:01:22.439
So, let see how would work. So, supposing
we have our old array of unsorted elements.

00:01:22.439 --> 00:01:28.211
So, what we do is, we start with the very
first element namely 74. So, we take 74, and

00:01:28.211 --> 00:01:32.740
we start a new stack. Now we have to take.
Now the top most elements at this point is

00:01:32.740 --> 00:01:38.049
now 32, to the left most in this case. So,
now we have to take 32, and since it is smaller

00:01:38.049 --> 00:01:46.550
it should go to the left of 74. So, we do
this, so we now get this array. Now we look

00:01:46.550 --> 00:01:52.210
at the next element; namely 89. And once again
it must go at the appropriate position with

00:01:52.210 --> 00:01:58.299
respect these two, so it must go to the right
of the 74, so we get this array. Now we take

00:01:58.299 --> 00:02:03.850
55, and we have to find out where it goes.
So we can start at end and say it is not here,

00:02:03.850 --> 00:02:08.479
it must go to the left of this.
Then we finally, find that this is the correct

00:02:08.479 --> 00:02:13.950
place for it to go. So, this is the insertion
step. We take each element, and we walk down

00:02:13.950 --> 00:02:20.620
to the point where we want to insert. So,
55 comes between 32 and 74. Now where does

00:02:20.620 --> 00:02:24.730
21 go. Well if we try to insert it, it turns
out, it must go all the way to beginning,

00:02:24.730 --> 00:02:28.980
because it is smaller than everything that
we have so far. So, this is the next step.

00:02:28.980 --> 00:02:35.630
And finally, when we do 64, it will come between
55 and 74. So, at each step we pick up the

00:02:35.630 --> 00:02:40.019
next element, and we insert it into the already
sorted segment that we have created with all

00:02:40.019 --> 00:02:43.400
the previous elements.

00:02:43.400 --> 00:02:50.210
So, we start by building a sorted sequence
with one element. So, this is called insertion

00:02:50.210 --> 00:02:56.330
sort. And we insert each unsorted element
into the correct place in the already sorted

00:02:56.330 --> 00:03:02.180
sequence. So, it is because of this insertion
step, that every element is inserted into

00:03:02.180 --> 00:03:05.190
its correct place. This is called insertion
sort.

00:03:05.190 --> 00:03:11.030
So, this is a very straight forward iterative
implementation again. So, what do is, we have

00:03:11.030 --> 00:03:19.790
an initial array A, from position 0 to n minus
1. So, what do; of course, is at the beginning

00:03:19.790 --> 00:03:24.240
we have to do nothing. So, we cannot assume
that we actually start with position 1. So,

00:03:24.240 --> 00:03:29.879
we start with position 1, and then we look
backwards. So, we start with the current position,

00:03:29.879 --> 00:03:37.180
and we work backwards, and so long as the
value that we are looking at, is smaller than

00:03:37.180 --> 00:03:42.870
the value to its left. We keep moving. So,
we have assumed that we have this swap operation,

00:03:42.870 --> 00:03:47.590
which basically takes two positions in an
array and exchanges them. So, swap A nextpos

00:03:47.590 --> 00:03:51.680
nextpos minus 1, means take the value at A
nextpos, take the value at A nextpos minus

00:03:51.680 --> 00:03:56.220
1, and swap them. As we explained at the beginning,
we can assume that such things are basic operations,

00:03:56.220 --> 00:04:00.840
it is convenient for us to express algorithm
like it, as adding this only adds a constant

00:04:00.840 --> 00:04:04.510
factor to the number of overall operations
that we have to do, which we can ignore in

00:04:04.510 --> 00:04:07.959
asymptotic complexity.
So, we swap each element with the element

00:04:07.959 --> 00:04:13.670
on its left, so long as it is, the element
on the left smaller, and we stop when we come

00:04:13.670 --> 00:04:17.420
to a position where the value on the left,
is greater than or equal to the current value,

00:04:17.420 --> 00:04:21.820
at this point we stop. So, this brings the
value that we started with, is in correct

00:04:21.820 --> 00:04:27.750
position. So, in general, if we had; say done
up to some i and then I start walking backward.

00:04:27.750 --> 00:04:35.870
Then so long as i is smaller than i minus
1, I will exchange. I will keep exchanging,

00:04:35.870 --> 00:04:41.470
until I reach a position, where a find that
the values on the left, are smaller than this

00:04:41.470 --> 00:04:46.680
value, and I will stop. So, this is a basic
loop, and I do this for all elements. So,

00:04:46.680 --> 00:04:50.040
for each element I have to insert it. So,
first time I have to insert it in a smaller

00:04:50.040 --> 00:04:55.200
segment. As I go along, the segment we have
to insert it in, becomes longer and longer.

00:04:55.200 --> 00:05:01.950
So, we can see now how this works, on an array
given to us. So, we first of all start with,

00:05:01.950 --> 00:05:08.750
looking at this segment. So, this is my initial
configuration. So, this is sorted, and this

00:05:08.750 --> 00:05:19.480
is unsorted. So, now, I will immediately see
that 32, is bigger than 74, so I will exchange,

00:05:19.480 --> 00:05:22.800
and then because it reaches the beginning.
So, one of the condition in that loop, is

00:05:22.800 --> 00:05:28.150
that if I reach beginning of the loop, so
if nextpos is equal to 0, I will also stop,

00:05:28.150 --> 00:05:34.160
if I found it to the left most position then
the loops terminates . So, having done that,

00:05:34.160 --> 00:05:43.150
then I have this. So, now I must try to insert
89 into this. So, I will find that 89 is already

00:05:43.150 --> 00:05:47.160
bigger than 74, nothing needs to be done.
So, the first nontrivial step that happens,

00:05:47.160 --> 00:05:53.180
is with 55. So, when I do 55, I compare it
with the 89. I find that 89 is bigger than

00:05:53.180 --> 00:05:59.530
55, I will exchange them. Now I will compare
55 with the element on its left 74.

00:05:59.530 --> 00:06:03.950
And then again it is in the wrong way, so
I will exchange. Finally, having found that

00:06:03.950 --> 00:06:09.900
55 is now bigger than 32, I will stop. So,
this is now the end of this phase. Now I will

00:06:09.900 --> 00:06:17.020
look at the next element to do, which is 21.
So, I will look at 21. So, 21 will get exchanged

00:06:17.020 --> 00:06:22.070
with 89. Then 21 will exchange, so it will
get exchanged all the way to the left, so

00:06:22.070 --> 00:06:27.640
I will exchange 21 with 74. Then I will exchange
21 with 55. Then I will exchange 21 with 32.

00:06:27.640 --> 00:06:30.810
And now once again I will stop, because I
have reached the left most position, there

00:06:30.810 --> 00:06:37.380
is nothing to the left. And the last round
I will take 64. So, now, this part is all

00:06:37.380 --> 00:06:43.180
sorted. So, I will take 64 and try to insert
it here, so it will swap with 89. It will

00:06:43.180 --> 00:06:49.440
swap with 74, and then stop. This is how insertion
sort works. This is a very intuitive sort.

00:06:49.440 --> 00:06:54.900
If you take a pack of card and try to sort
it, typically this is how you would sort.

00:06:54.900 --> 00:07:00.500
So, if you look at the analysis, it is quite
similar to selection sort that we saw before.

00:07:00.500 --> 00:07:05.500
So, inserting a value means we have to walk
down that segment till the very end. Now of

00:07:05.500 --> 00:07:12.340
course, one might argue, that to find the
position to insert, you can use binary search.

00:07:12.340 --> 00:07:15.870
We need not go one element at a time. If you
want to actually find the position where it

00:07:15.870 --> 00:07:19.840
must go, we can use binary search, but even
if you find the position where it must go

00:07:19.840 --> 00:07:24.180
in logarithmic time. You need to shift all
the elements, and that is what really takes

00:07:24.180 --> 00:07:28.430
linear time. You need to actually make space
for this. So in the worst case, you might

00:07:28.430 --> 00:07:33.090
have to put it in the left most position.
So, all the k elements which are already there

00:07:33.090 --> 00:07:37.370
must be shifted right by 1, and that takes
k steps. So, binary search, although it can

00:07:37.370 --> 00:07:42.080
help as find the position faster, does not
really help us to implement insert any faster.

00:07:42.080 --> 00:07:47.590
So, insert takes linear time for a segment,
and these segments keep growing. Initially

00:07:47.590 --> 00:07:52.441
I want to insert A 1 into segment of size
1, then A 2 into segment of size 2 and so

00:07:52.441 --> 00:07:58.270
on. So, I have 1 plus 2 plus 3 up to n minus
1; finally, A n minus 1 must be inserted in

00:07:58.270 --> 00:08:03.440
the segment A 0 to A n minus 2, which is of
length n minus 1. So, again I have t of n

00:08:03.440 --> 00:08:09.310
is 1 plus 2 up to n minus 1, and this is just
a variation of this summation we have seen

00:08:09.310 --> 00:08:13.800
many times before, it is n into n minus 1
by 2. So, this is again an order n square

00:08:13.800 --> 00:08:16.000
sort.

00:08:16.000 --> 00:08:22.360
So, once again as we saw for selection sort.
There is a natural way to think of insertion

00:08:22.360 --> 00:08:28.460
sort as a recursive thing. We sort part of
the array, and then we insert an element into

00:08:28.460 --> 00:08:36.580
that to grow it. So, in this case we think
of the array as being in 2 components. So,

00:08:36.580 --> 00:08:44.750
we have a sorted portion, and an unsorted
portion. So, what we do is, we take the first

00:08:44.750 --> 00:08:51.990
element here and insert it and then we recursively
apply the algorithm to the rest of the unsorted

00:08:51.990 --> 00:08:57.390
portion. So, if A 0 to i minus 1. So, if this
is position i and this is position i minus

00:08:57.390 --> 00:09:02.320
1. So, i minus 1 is the last sorted position,
i is the first unsorted position. Then we

00:09:02.320 --> 00:09:08.330
insert A i into the sorted portion. And then
we recursively sorted A i plus 1 onwards.

00:09:08.330 --> 00:09:13.740
And once again when i is actually here, at
n minus 1, then we do not have to do anything,

00:09:13.740 --> 00:09:16.440
so we can just trivially return.

00:09:16.440 --> 00:09:25.020
So, now we have a recursive formulation in
two parts. So, we have insertion sort itself,

00:09:25.020 --> 00:09:31.080
which says sort this unsorted segment from
start to n minus 1. So, if start is already

00:09:31.080 --> 00:09:37.280
at n minus 1 return; otherwise insert the
value at position start into the rest of A,

00:09:37.280 --> 00:09:42.481
which we will see below. And then recursively
sort the rest of the array from start plus

00:09:42.481 --> 00:09:46.430
1 onwards. So, what does the insert do? Well
it starts at the position start and tries

00:09:46.430 --> 00:09:51.020
to insert it into the segment 0 to start minus
1. So, it works backwards exactly as we had

00:09:51.020 --> 00:09:55.450
done in the iterative thing. It finds the
first position such that the value on the

00:09:55.450 --> 00:10:01.650
left, is at least as small as the value currently
looking for and stops there. So, this insert

00:10:01.650 --> 00:10:05.860
is basically what was in the body of the iterate
loop, but instead of doing an outer loop,

00:10:05.860 --> 00:10:10.020
we do it recursively. So, how much time does
this take.

00:10:10.020 --> 00:10:13.640
Once again this is just give you practice
in looking at recursively algorithms and writing

00:10:13.640 --> 00:10:18.779
down the analysis. So, whenever we have a
recursively algorithm we write a recurrence;

00:10:18.779 --> 00:10:24.250
that is, we write of formulation of t of n
in terms of smaller values of t. So, let us

00:10:24.250 --> 00:10:29.840
try to analyze this recursively algorithm.
So, we will analyze it, looking at a slightly

00:10:29.840 --> 00:10:35.870
differently from the way we have formulated
the algorithm. So, if you want to sort A 0

00:10:35.870 --> 00:10:46.230
to A n minus 1, then what we are doing is,
we are recursively sorting this segment, and

00:10:46.230 --> 00:10:51.920
then inserting this value. So, it takes time
t n to sort the entire thing. This breaks

00:10:51.920 --> 00:10:58.180
up into taking time t n minus 1 to sort the
first part up to n minus 2, and then n minus

00:10:58.180 --> 00:11:02.960
1 step to do the insert right. So, we get
same recurrence as we did for selection sort

00:11:02.960 --> 00:11:10.110
t of n is t of n this is the insert space,
and plus t of n minus 1 which is the recursive

00:11:10.110 --> 00:11:13.080
phase.
And if we expand this out exactly as we did

00:11:13.080 --> 00:11:18.010
before, we get n minus 1 plus n minus 2 down
to n, which is n into n minus 1 by 2, which

00:11:18.010 --> 00:11:22.730
is order n square. So, again there is no different
between time for the recursive and iterative

00:11:22.730 --> 00:11:26.920
versions; except that one should keep in mind
in general that, recursive calls are more

00:11:26.920 --> 00:11:33.340
expansive then iterative loops. We will come
back to this point a little later, but otherwise

00:11:33.340 --> 00:11:37.420
if we count recursive calls calling a function
as a basic operation, then there is no difference

00:11:37.420 --> 00:11:41.310
between the recursive and the iterative version.
The recursive version is sometimes easier

00:11:41.310 --> 00:11:46.620
to conceptually understand and to code.

00:11:46.620 --> 00:11:52.800
So, what we have seen is that, the two natural
algorithms that we would typically apply when

00:11:52.800 --> 00:11:58.381
we do something manually; selection sort and
insertion sort are both order n square. There

00:11:58.381 --> 00:12:02.320
is another algorithm which you may come across
which we will not discuss in this course called

00:12:02.320 --> 00:12:08.430
bubble sort, which is not something that we
would do naturally, but it seems to be a favorite

00:12:08.430 --> 00:12:14.480
way of describing how to do the things on
a computer. So, bubble sort basically does

00:12:14.480 --> 00:12:18.480
this insertion kind of swapping, except it
takes the maximum or minimum value depending

00:12:18.480 --> 00:12:21.990
on which you want to do. Say it takes the
maximum value and moves it to one end of the

00:12:21.990 --> 00:12:26.010
array. So, then you have like selection sort,
the largest value at one end. Then you go

00:12:26.010 --> 00:12:29.410
back to the beginning, and again you keep
looking at adjacent values, and take the second

00:12:29.410 --> 00:12:34.510
largest value to the second last position
and so on. So, bubble sort is also n Square,

00:12:34.510 --> 00:12:39.120
but as we have seen n square algorithms are
not really feasible for large values of n.

00:12:39.120 --> 00:12:43.741
So, if we have n above about 10000, somewhere
between 10 to the 4 and 10 to the 5, then

00:12:43.741 --> 00:12:47.860
n square is going to take several hundred
seconds to execute, and therefore, this is

00:12:47.860 --> 00:12:50.820
not going to be useful for large bodies of
data.

00:12:50.820 --> 00:12:56.460
But this is not to say that these algorithms
are all equally bad. In particular it turns

00:12:56.460 --> 00:13:01.870
out that if you actually look at experimental
evidence, then insertion sort usually behaves

00:13:01.870 --> 00:13:06.000
better than selection sort, and both of them
are better than bubble sort. And to think

00:13:06.000 --> 00:13:10.680
about why insertion sort behaves well, just
imagine what happens when we apply insertion

00:13:10.680 --> 00:13:15.780
sort to an already sorted list. Whenever we
want to insert something into the already

00:13:15.780 --> 00:13:19.870
sorted list, we will find that it is already
in the correct position. So, the bottle neck,

00:13:19.870 --> 00:13:23.560
which is the insert phase, is the bottle neck.
The insert face will basically terminate after

00:13:23.560 --> 00:13:29.779
one comparison. So, insertion sort will essentially
become linear time, if we apply it to an already

00:13:29.779 --> 00:13:34.590
sorted list. So, this is why in many situation;
insertion sort actually behaves a little better

00:13:34.590 --> 00:13:39.300
than other order n square sorts, but in general
order n square sorting algorithms are not

00:13:39.300 --> 00:13:44.460
acceptable, and we would like to look at more
clever ways of sorting our data, because in

00:13:44.460 --> 00:13:46.810
order to sort large volumes of data this is
impractical.

