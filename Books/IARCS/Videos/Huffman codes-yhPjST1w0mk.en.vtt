WEBVTT
Kind: captions
Language: en

00:00:01.770 --> 00:00:06.020
For the last example of a greedy algorithm
in this course, we will look at a problem

00:00:06.020 --> 00:00:09.700
communication theory, we will look at the
problem of Huffman Codes.

00:00:09.700 --> 00:00:16.150
So, when we communicate, we have to transmit
information from one place to another place.

00:00:16.150 --> 00:00:20.520
So, we might be working in some language like
English, Hindi or whatever, but if were using

00:00:20.520 --> 00:00:24.570
computers for example, to transmit our data,
we know that they must send this information

00:00:24.570 --> 00:00:30.571
in binary strings. So, our typical goal is
to take an alphabet, and then encoded it over

00:00:30.571 --> 00:00:34.989
strings of 0 and 1, so that at the other end,
we can decoded and recover the message.

00:00:34.989 --> 00:00:43.989
So, if you have say the 26 lower case letters
a to z, then it is easy to see that we need

00:00:43.989 --> 00:00:50.370
to if you want to encode each letter as a
fixed sequence of 0Õs and 1Õs by fixed length,

00:00:50.370 --> 00:00:55.649
then we will need to use 5 bits per letter,
because if you use only 4 bits, we can only

00:00:55.649 --> 00:01:01.850
get 16 different combinations, with 5 bits
we can get 32 different combinations. So,

00:01:01.850 --> 00:01:11.990
now a natural question is, can we do something
clever about using different length encoding

00:01:11.990 --> 00:01:17.619
for different letters, so that more frequent
letters get send with shorter inputs. So,

00:01:17.619 --> 00:01:22.139
can we optimize the amount of data we actually
transfer in order to send the message from

00:01:22.139 --> 00:01:24.280
one place to another?

00:01:24.280 --> 00:01:32.810
So, this brings us to the idea having a variable
length encoding, where we use different strings

00:01:32.810 --> 00:01:36.759
of different length for different letters
in the alphabet. So, one of the most famous

00:01:36.759 --> 00:01:41.340
examples of the variable length encoding is
the classical Morse code, which is developed

00:01:41.340 --> 00:01:45.990
by Samuel Morse from the telegraph who is
invented. So, this was done using a mechanical

00:01:45.990 --> 00:01:52.560
device by clicking on a contact and it will
produce long and short clicks. So, the short

00:01:52.560 --> 00:01:56.979
clicks are called dots and the long clicks
called dashes, we can as well think of them

00:01:56.979 --> 00:02:02.599
as representing the bits 0 and 1.
So, in the Morse code encoding, different

00:02:02.599 --> 00:02:07.649
letters do have different encodings and in
English e is the most frequent letter and

00:02:07.649 --> 00:02:13.850
t is another very frequent letter. So, Morse
assigned them codes of a dot, that is 0 for

00:02:13.850 --> 00:02:20.860
e and a dash, that is 1 for t, then a Morse
took other frequent letters, such as a and

00:02:20.860 --> 00:02:25.790
gave them two letter encodings. So, a is encoded
as dot dash, where 0 and 1.

00:02:25.790 --> 00:02:31.460
Now, the problem with MorseÕs encoding is
that it is ambiguous, when you come to decoding.

00:02:31.460 --> 00:02:38.280
So, for instance, if we look at the word,
the sequence 0 1, then we do not know whether

00:02:38.280 --> 00:02:43.690
we should interpret each of these as a one
letter code and get e t e t, all for instance

00:02:43.690 --> 00:02:49.780
we should think of this as 2 two letter of
codes and get a a and so on. So, depending

00:02:49.780 --> 00:02:56.330
on whether we stop it is 0 or extends 0 to
0 1, we can get many different interpretations.

00:02:56.330 --> 00:03:01.850
Now, in practice in Morse code, what we used
to happen is that the operator gives a slide

00:03:01.850 --> 00:03:07.180
pause indicating the end of the letter. So,
therefore, effectively Morse code is not a

00:03:07.180 --> 00:03:12.540
binary code, but it is a three letter code
0 1 and pause, now we are using of course,

00:03:12.540 --> 00:03:16.960
digital computers, we do not want to go to
three letters. So, we want to efficiently

00:03:16.960 --> 00:03:21.060
do these using just two letters.

00:03:21.060 --> 00:03:28.690
So, in order to make a variable length code
an unambiguous decodable, we need what is

00:03:28.690 --> 00:03:34.900
called a prefix quantity. When we read through
a sequence of 0Õs and 1Õs, we should be

00:03:34.900 --> 00:03:39.350
unambiguously clear, whether we have read
a letter or there is more to read. We should

00:03:39.350 --> 00:03:43.690
not be like the earlier case, where we have
read 0 and we do know, whether we stop at

00:03:43.690 --> 00:03:50.840
0 and call it an e in the Morse code setting
or we want to call it an a which is 0 1.

00:03:50.840 --> 00:03:55.950
So, we are going to use this capital letter
E to denote the encoding the function. So,

00:03:55.950 --> 00:04:00.830
E of x is the encoding of the letter. So,
here is an example, so we have five letters

00:04:00.830 --> 00:04:06.090
a, b, c, d, e and now, you can check that
none of these encodings can be extended to

00:04:06.090 --> 00:04:09.150
anything. I do not have, if I see 1 1, it
must be an a. There is, no other code which

00:04:09.150 --> 00:04:15.510
starts with 1 1. If I see 0 0 it is not a
code, but 0 0 1 is a code, so 0 1 cannot be

00:04:15.510 --> 00:04:20.449
extend and so on. So, each of these cannot
be extended to be the code of any other letter.

00:04:20.449 --> 00:04:26.569
So, now when we get along sequence like this,
there is no doubt, the first point when I

00:04:26.569 --> 00:04:29.680
completed a letter is 0 0 1 and this is a
c.

00:04:29.680 --> 00:04:33.889
The next point when I complete the letter
is three 0Õs and it is an e, then I read

00:04:33.889 --> 00:04:39.490
another c and then an a and then a b. So,
if we have the prefix code property, that

00:04:39.490 --> 00:04:44.979
is no letter is encoded to a string which
is the prefix of the encoding or some other

00:04:44.979 --> 00:04:50.409
letter, then we have unambiguous decoding
possible and this is very important.

00:04:50.409 --> 00:04:57.939
So, our goal is to find optimal prefix codes.
So, we need to talk about what we mean by

00:04:57.939 --> 00:05:04.930
optimality. So, remember we said that our
goal is to assign shorter codes to more frequent

00:05:04.930 --> 00:05:09.400
letters. So, somehow we have to determine,
what are more frequent and less frequent letters.

00:05:09.400 --> 00:05:14.650
So, people have measure the frequency of the
occurrence of each letter and different languages,

00:05:14.650 --> 00:05:18.979
so this is a very language specific thing.
So, this optimality is something which is

00:05:18.979 --> 00:05:27.099
optimal for English, may not work of French
or any other Spanish or something. So, you

00:05:27.099 --> 00:05:32.360
take a large body of text in a particular
language and you count the number of aÕs

00:05:32.360 --> 00:05:34.879
bÕs cÕs dÕs and eÕs, and then you just
look at the fraction, out of the total number

00:05:34.879 --> 00:05:38.440
of letters across all the steps, how many
are eÕs, how many bÕs, how many are cÕs.

00:05:38.440 --> 00:05:43.569
So, this is a kind of statistical estimate
of the average frequency of this.

00:05:43.569 --> 00:05:47.520
So, this frequency would be a fraction, what
fraction of the letter over a large body of

00:05:47.520 --> 00:05:52.259
text will be eÕs, what fraction will be cÕs
and these fraction will add up to one, because

00:05:52.259 --> 00:05:56.240
every letter would be one of them. So, the
fraction of a is plus, the fraction of b is

00:05:56.240 --> 00:06:00.420
plus, fraction of c is and so on is going
to added to 1 and because of this, we can

00:06:00.420 --> 00:06:03.199
also think of this statistical estimate or
a kind of probability.

00:06:03.199 --> 00:06:07.500
Like, if I give you a random letter, if I
look at the piece of text and pickup a random

00:06:07.500 --> 00:06:12.220
letter from the text, what is the probability
that x, well it is just be the frequency of

00:06:12.220 --> 00:06:17.139
x across all the text f of x. So, these will
add up to 1.

00:06:17.139 --> 00:06:24.669
So, now, we have a message, it consists of
some n symbols. So, we have M 1, M 2 up to

00:06:24.669 --> 00:06:31.460
M n, so these are n symbols. Now, we know
that if I take a particular letter x, then

00:06:31.460 --> 00:06:40.190
f x fraction of these are x, so in other words,
if I take n and I multiply by a fraction is

00:06:40.190 --> 00:06:46.319
say, if I fix is say one third, then one third
of n. So, n by 3 of these symbols will actually

00:06:46.319 --> 00:06:54.300
be the letter x and now, each of these Xs
is going to be represented by it is encoding.

00:06:54.300 --> 00:07:01.030
So, supposing it is 0 1 0 then each x is going
to represent by 3 bits, so then n into f x

00:07:01.030 --> 00:07:06.469
is the number of times I see x and this into
the length of this encoding is going to give

00:07:06.469 --> 00:07:11.619
me the total number of bits taken to encode
all the xÕs in this message. Now, if I do

00:07:11.619 --> 00:07:22.559
this for every letter, so if I take the summation
over every y or every x in my alphabet, n

00:07:22.559 --> 00:07:27.680
times the frequency of the letter times the
encoding length of that letter.

00:07:27.680 --> 00:07:32.559
So, this tells me how many bits I need to
encode that particular letter, add up all

00:07:32.559 --> 00:07:40.050
the letters, I get the total length of the
encoded message. And if I do not include this

00:07:40.050 --> 00:07:45.369
n, notice that n is not a part of the sum,
it is an independent thing, it is a fraction

00:07:45.369 --> 00:07:57.069
of any n. If I just look at the total weighted
average of the lengths of the encodings, then

00:07:57.069 --> 00:08:00.830
this is if you study probability theory, what
is called the expected length of the encoding.

00:08:00.830 --> 00:08:08.001
So, this is the average number of bits, I
use for a letter.

00:08:08.001 --> 00:08:12.159
So, let us work out how this, so suppose we
take our earlier example of 5 letters, now

00:08:12.159 --> 00:08:17.759
we insert some fictitious information about
frequencies. So, this all these five values

00:08:17.759 --> 00:08:25.089
are fraction between 0 and 1, they all add
to 1. Then if I do this summation over x of

00:08:25.089 --> 00:08:33.010
f of x times the length of E of x, then I
have 0.32 times 2, because the encoding of

00:08:33.010 --> 00:08:40.140
A is two letters, then I have 0.25 times to
2, because the encoding E is two letters and

00:08:40.140 --> 00:08:43.330
so on.
So, I have these five terms a, b, c, d, e

00:08:43.330 --> 00:08:50.070
and then I add it up and I get 2.25, so it
says that I need an average 2.25 bits per

00:08:50.070 --> 00:08:54.130
letter. Of course, I do not use 2.25 bits
per letter, but what it says this for instance,

00:08:54.130 --> 00:09:01.990
if I have a 100 letters, I would expect to
see 225 bits in the output encoding. Now,

00:09:01.990 --> 00:09:07.850
a very specific kind of prefix code is the
fixed length code, where just by the fact

00:09:07.850 --> 00:09:11.780
that every code to the fixed length, I know
exactly where each one is.

00:09:11.780 --> 00:09:16.550
So, supposing I use 3 bits in this case, if
I want to fixed length code of this, then

00:09:16.550 --> 00:09:21.200
there are five letters, I cannot do it with
2 bits, because I only get four different

00:09:21.200 --> 00:09:26.550
combinations. So, I need 3 bits, if I use
some 3 bit code, then every 3 bits will be

00:09:26.550 --> 00:09:31.440
one letter. So, in the fixed length encoding
in this, I will use 3 bits for letters, so

00:09:31.440 --> 00:09:35.740
therefore clearly the number of bits per letter
is 3, because I am using 3 for every one of

00:09:35.740 --> 00:09:39.870
them. And so by going to a variable length
code encoding which takes in to upon the frequency

00:09:39.870 --> 00:09:44.420
and actually savings it is to a sending 300
bits for 100 character, it send into 225.

00:09:44.420 --> 00:09:49.370
So, we have 25 percent saving, so this is
what we are trying to get at.

00:09:49.370 --> 00:09:58.870
So, in this example in the previous thing
we have two frequencies 0.2 and 0.18, the

00:09:58.870 --> 00:10:04.590
0.18 means d is less frequency than c, but
somehow we assigned c to be a longer code.

00:10:04.590 --> 00:10:11.270
So, this violated our basic principle that
shorter code should be assigned to more frequent

00:10:11.270 --> 00:10:14.650
letters. So, if you see a pair of letters
which are where one is more frequent than

00:10:14.650 --> 00:10:17.850
other, I expected to get a shorter code and
I had not done so.

00:10:17.850 --> 00:10:22.950
So, if I invert that, so supposing I now assign
a three letter code to d and a two letter

00:10:22.950 --> 00:10:27.840
code to c, then these two terms change the
other terms, though the encoding may have

00:10:27.840 --> 00:10:34.920
differ, the length do not change. So, then
I get instead of 2.25, I get on to 2.23, so

00:10:34.920 --> 00:10:42.470
what this say is that looking at different
encodings I could get different A B L values,

00:10:42.470 --> 00:10:51.320
this average bits per letter. So, now, our
goal is to find an assignment capital E which

00:10:51.320 --> 00:10:58.590
minimizes this quantity. So, in our coding
the average efficient is possible.

00:10:58.590 --> 00:11:05.680
So, to get to this, it is useful to think
of these encodings as binary trees, so in

00:11:05.680 --> 00:11:09.140
a binary tree I can interpret directions as
0 and 1, so typically left is 0 and right

00:11:09.140 --> 00:11:16.360
is 1. So, now, if I read of a path in a binary
tree, it is also a binary sequence. So, this

00:11:16.360 --> 00:11:23.280
path is 1 1 1 on the right for example and
this path for example the 0 1 and this path

00:11:23.280 --> 00:11:30.820
is 0 0 0. Now, if I read of a path and then
I find the letter of that label, then it is

00:11:30.820 --> 00:11:34.680
as good as saying that path labels that letter
is encoded by that path.

00:11:34.680 --> 00:11:42.480
So, here is because e is has the encoding
0 0 0 in the binary tree, I will follow the

00:11:42.480 --> 00:11:48.590
path 0 0 0 and label that corresponding letter
that vertex by e. Now, because it is a prefix

00:11:48.590 --> 00:11:54.740
code, if 0 0 0 labels e, they will not be
any code which says 0 0 0 and something more,

00:11:54.740 --> 00:12:00.720
they will not be another label below it. So,
these labels will not extend to other label,

00:12:00.720 --> 00:12:05.010
I will not find an f below d, because otherwise
it not a prefix code, I do 1 0 and I get a

00:12:05.010 --> 00:12:09.400
t, but I do 1 0 something else, then I get
an f. So, the code for f extends the code

00:12:09.400 --> 00:12:14.340
for d, this is not enough. So, in a prefix
code this cannot happen, so therefore, all

00:12:14.340 --> 00:12:21.280
the labels are actually at leaf nodes, there
it nodes which have are more successors.

00:12:21.280 --> 00:12:30.191
So, here is an encoding for the other scheme
that we had, where we exchanged the values

00:12:30.191 --> 00:12:35.050
of c and d. So, now c has a two letter code
and d has a three letter code, this is indicated

00:12:35.050 --> 00:12:39.470
by the in depth now, the depth this is path,
the length of the path is the depth of the

00:12:39.470 --> 00:12:48.520
node. So, c in our earlier thing was a depth
3, and now it is a depth 2 and the d was depth

00:12:48.520 --> 00:12:55.330
2 and now it is a depth 3. So, we want to
basically put thing which have higher frequencies,

00:12:55.330 --> 00:12:59.890
higher up in the tree at lesser depth.

00:12:59.890 --> 00:13:09.880
So, having encoded look at are encoding the
binary tree, we will now make a couple of

00:13:09.880 --> 00:13:14.270
observation, three observation of bottom which
will be useful prove to develop an optimal

00:13:14.270 --> 00:13:21.130
algorithm and prove it is optimal. So, the
first thing is that in such a tree, if it

00:13:21.130 --> 00:13:24.500
is optimal, every node will either have no
children will be a leaf or it will have two

00:13:24.500 --> 00:13:33.770
children. So, this is what we called a Full.
So, every optimal tree is full, now is easy

00:13:33.770 --> 00:13:38.750
to see this, because the supposing the claim,
we other optimal tree in which somewhere in

00:13:38.750 --> 00:13:46.160
between, we had a node which had only one
child. Then, this child can effectively will

00:13:46.160 --> 00:13:51.540
be promoted, we can remove this node completely
and we can shrink the tree along this direction

00:13:51.540 --> 00:13:58.860
a nothing will change, except that the depth
of the node is below become less. So, in fact,

00:13:58.860 --> 00:14:04.540
we will possibly get a shorter average bit
length then we had, therefore by having a

00:14:04.540 --> 00:14:09.120
Singleton, either only a left child or right
child, we cannot be optimal. So, the every

00:14:09.120 --> 00:14:13.510
node must either 0 or two children.

00:14:13.510 --> 00:14:17.530
The next property is exactly what we saw the
earlier thing, which is that, if I have two

00:14:17.530 --> 00:14:26.220
nodes x and y, such that, x is higher than
y, so x is at some level and y is different

00:14:26.220 --> 00:14:33.070
level. Then, x has a shorter encoding then
y, this must mean that f of x is at least

00:14:33.070 --> 00:14:38.860
as much f of y, in other word, when I go down
the tree my frequency cannot increase, because

00:14:38.860 --> 00:14:42.720
if f of y would bigger than f of x, that if
I had more ys than xs in my text. Then, I

00:14:42.720 --> 00:14:46.830
will just exchange these two, I would find
a better encoding by putting y here and x

00:14:46.830 --> 00:14:50.331
here.
Because, now if I do f of y time the length

00:14:50.331 --> 00:14:55.410
of y and the depth y in this tree, then it
will reduce, because the depth of y is reduce

00:14:55.410 --> 00:14:59.410
and this is the higher multiply. So, therefore,
if I had a higher thing below, then I could

00:14:59.410 --> 00:15:03.290
exchange the letter and get better tree and
that does not happen in then optimal tree,

00:15:03.290 --> 00:15:11.310
so then the optimal tree, if I go down the
tree, I only find lower frequency letters.

00:15:11.310 --> 00:15:17.290
The final property is to do with leaves at
the lowest level, so supposing I have the

00:15:17.290 --> 00:15:23.610
leaf at the lowest leaf, so this is some leaf
of a lowest level. So, I know because it is

00:15:23.610 --> 00:15:30.210
an optimal tree, it cannot be a isolated child,
it must have a sibling so I go up and come

00:15:30.210 --> 00:15:34.770
down, I must have a sibling. Now, there are
two possibilities, the two possibilities are

00:15:34.770 --> 00:15:46.630
this is a leaf or the other possibility is
that, this is not a leaf, the claim if that

00:15:46.630 --> 00:15:53.210
if it is not a leaf, then it must have children.
So, then there are leaves here which have

00:15:53.210 --> 00:16:01.320
at the lower level, than x, but x is assumed
to be a maximum depth d. So, maximum depth

00:16:01.320 --> 00:16:05.952
leaf cannot have sibling, which is not a leaf,
because its sibling it would have a children,

00:16:05.952 --> 00:16:13.760
which have to higher depth. So, therefore,
if I have a maximum depth leaf in my optimal

00:16:13.760 --> 00:16:21.800
tree, then it will occur as a pair with another
maximum depth leaf.

00:16:21.800 --> 00:16:28.100
And so this is a conclusion in that leaves
of maximum depth occurred in pairs and then

00:16:28.100 --> 00:16:33.230
we know that because frequencies keep of dropping
as we go down increasing in depth, these pairs

00:16:33.230 --> 00:16:37.650
must have the lowest frequency, among the
lowest frequencies. So, in order to develop

00:16:37.650 --> 00:16:42.170
the solution, we will use recursion, so what
we will do is, we will say, let us look in

00:16:42.170 --> 00:16:46.510
the overall table that we start with and pick
two letters, which have the lowest frequency.

00:16:46.510 --> 00:16:53.850
So, we can assign them the longest codes,
so they can be put at the lowest level and

00:16:53.850 --> 00:16:57.410
then we know that the lowest level leaves
occur in pairs. So, let us assume that these

00:16:57.410 --> 00:17:02.970
will be paired out, so we will assign these
lowest frequency letters x and y, to a pair

00:17:02.970 --> 00:17:08.560
of leaves maximum depth, left and right does
not matter, because so the depth that matters.

00:17:08.560 --> 00:17:16.040
So, now, the recursive a solution will say,
that how do a figure of what the rest of the

00:17:16.040 --> 00:17:21.800
tree looks like, well if I have a situation,
where I have decided x and y go here. Then,

00:17:21.800 --> 00:17:28.809
I will kind of treat, this is a unit and make
a new letter call x, y and give it the cumulative

00:17:28.809 --> 00:17:34.020
frequency effects plus x, y of the old two
letter. So, construct the new alphabet in

00:17:34.020 --> 00:17:41.250
which I drop x and y and I add a new composite
of hybrid letter x, y; whose frequency is

00:17:41.250 --> 00:17:47.190
going to be f x plus f y.
Now, recursion kicks in, I have a k minus

00:17:47.190 --> 00:17:52.690
1 letter alphabet, so I have recursively find
and optimal encoding of that. Now, before

00:17:52.690 --> 00:17:59.280
coming to how to adapt the solution, the recursive
ends when have a only two letters, for two

00:17:59.280 --> 00:18:03.970
letters, the optimal solution is to build
the tree which exactly two leaves, label 0

00:18:03.970 --> 00:18:10.850
and 1 at the path. So, this is the base case,
if I have more than two letters I will recursively

00:18:10.850 --> 00:18:14.750
construct tree to the smaller thing and then
I will come back and now, the tree that I

00:18:14.750 --> 00:18:18.400
constructed I will have some where the leaf
label x y.

00:18:18.400 --> 00:18:23.540
Now, x y is not a letter, so what I do is,
I will replace this, write new two leaves

00:18:23.540 --> 00:18:28.900
called x and y. So, I will go from the tree
over a A prime to a tree over A by doings.

00:18:28.900 --> 00:18:35.270
So, this is an algorithm called by develop
Huffman and this type of coding is call Huffman

00:18:35.270 --> 00:18:36.270
coding.

00:18:36.270 --> 00:18:41.760
So, let us look at this example that we had
earlier, so here the two lowest frequency

00:18:41.760 --> 00:18:50.180
letters d and e. So, we merge them into the
new letter d, e and this is a frequency 0.23,

00:18:50.180 --> 00:18:57.140
because it is 0.18 plus 0.05. Now, these two
are a two lowest letters, so we merge them

00:18:57.140 --> 00:19:04.730
and we get a new letter c, d, e of cumulative
frequency 0.43, which is sum of all the frequencies

00:19:04.730 --> 00:19:08.559
of the two values.
Now, it turns out that, these two are the

00:19:08.559 --> 00:19:13.100
smaller two. So, I merge them into the letter
a, b and now, I have reached my base case

00:19:13.100 --> 00:19:18.590
where have exactly two letters. So, I can
set of the trivial tree this two letters,

00:19:18.590 --> 00:19:24.480
label 0 and 1. And now I work backwards, so
the last thing that I did was to merge a and

00:19:24.480 --> 00:19:28.390
b, now I will take this a and b thing and
split it has a and b.

00:19:28.390 --> 00:19:34.630
I will split a, b as a and b, I will get this
tree, then the previous step was to combine

00:19:34.630 --> 00:19:41.260
c, d e into c and d, e. So, I am going to
the split this c and d, e.

00:19:41.260 --> 00:19:47.940
And finally, I am going to split this up is
d and e. So, this is HuffmanÕs algorithm

00:19:47.940 --> 00:19:52.830
and by recursively combining the two lowest
frequency nodes, and then taking the composite

00:19:52.830 --> 00:19:58.651
node and splitting them back up to it is.

00:19:58.651 --> 00:20:02.809
So, to show that this algorithm is the optimal,
we go by induction in the size in the algorithm.

00:20:02.809 --> 00:20:06.761
Now, clearly when I have only two letters,
I cannot do any better than assign the one

00:20:06.761 --> 00:20:12.260
of them 0 and one of them 1, so the base case
is optimal. So, we will assume that this optimal

00:20:12.260 --> 00:20:17.280
for k minus 1 letters and now show that also
optimal for k letters.

00:20:17.280 --> 00:20:25.840
So, recall that, we went to k minus 1 by combining
the two lowest frequency letters as 1, constructing

00:20:25.840 --> 00:20:32.309
an optimal tree for the smaller alphabet and
then expanding the x, y to get a new. So,

00:20:32.309 --> 00:20:39.690
the claim is when I go from the tree over
k minus 1 letters to the tree over k letters,

00:20:39.690 --> 00:20:44.350
the cost is going to increase, but this cost
is going to be fixed by whichever letters

00:20:44.350 --> 00:20:48.410
I choose to contract.
So, if I choose x and y to merge to go from

00:20:48.410 --> 00:20:54.200
T to T prime, then the amount by the which
the average bits per letter is going to change

00:20:54.200 --> 00:20:57.610
is exactly the frequency of this combine letter
f x y. So, the deterministically fixed by

00:20:57.610 --> 00:21:04.350
which one I choose, then even though I do
know the cost of the trees directly, I can

00:21:04.350 --> 00:21:09.421
tell you that the cost is going to be different
by this amount.

00:21:09.421 --> 00:21:23.310
This is not very difficult to prove, so in
that summation that we had, from the tree

00:21:23.310 --> 00:21:27.800
notation remember this depth of z is the same
as the length of the encoding of set, because

00:21:27.800 --> 00:21:32.220
the depth exactly a reflects the length of
the string use to encoded. So, this is our

00:21:32.220 --> 00:21:38.590
A B L calculation. Now, for every node other
than the x, y and x y, there are exactly at

00:21:38.590 --> 00:21:42.090
the same position in T and T primes.
So, this these sum summation with terms do

00:21:42.090 --> 00:21:47.950
not change, so the only changes are these
three nodes. So, what I will do, I will be

00:21:47.950 --> 00:21:55.210
going to T prime to T is I will remove this
contribution of the composite letter xy. And

00:21:55.210 --> 00:22:01.810
then at a next level which is 1 plus the depth
of the xy, I will add the node f x and I add

00:22:01.810 --> 00:22:08.630
the node f x and I will get the components
x y, f x times that plus x y times, I am subtracting

00:22:08.630 --> 00:22:14.220
this amount in the left, then I am adding
this amount to the right.

00:22:14.220 --> 00:22:21.000
So, now, actually f of x y is nothing but
f x plus f y. So, this left hand side term

00:22:21.000 --> 00:22:28.510
is actually this right hand side component
depth of x y, times of x plus y. So, I am

00:22:28.510 --> 00:22:33.540
subtracting this and adding it back, so the
cancel each other, so therefore, all am left

00:22:33.540 --> 00:22:41.890
with is one times f x plus y which is f x
by f y or f x y. So, therefore I am going

00:22:41.890 --> 00:22:47.320
from T prime to T, the crucial thing is only
depend for which letters I have contract,

00:22:47.320 --> 00:22:49.930
that fixes the difference uniquely.

00:22:49.930 --> 00:23:00.040
Now, let us assume that, we know how to solve
all k minus 1 size alphabets efficiently and

00:23:00.040 --> 00:23:04.880
we have done this recursive thing to construct
the tree for size k. Suppose, this is another

00:23:04.880 --> 00:23:10.200
strategy would produce the better tree for
size k, so this another tree candidate tree

00:23:10.200 --> 00:23:15.200
S produce by some different strategy, whose
is average bits for letter is strictly better

00:23:15.200 --> 00:23:21.870
than the one that we construct recursive.
Now, in S, we know for sure that these two

00:23:21.870 --> 00:23:27.360
letters that we use the in recursive construction
x and y. So, they occur somewhere at the bottom

00:23:27.360 --> 00:23:34.230
of this tree. So, this is my tree S, these
must be leave nodes, because they have the

00:23:34.230 --> 00:23:38.600
lowest frequency is over all the letters,
so must be a maximum depth, that they may

00:23:38.600 --> 00:23:42.490
not be next to each other. But, it does not
matter, because since they are both at maximum

00:23:42.490 --> 00:23:48.860
depth, I can move them around, this step,
I can move letters around, I can reassign

00:23:48.860 --> 00:23:53.770
the two other leaf to a sender.
Such that, I come with the configuration I

00:23:53.770 --> 00:24:02.510
come to new S, I call it S again, where actually
have x and y together. I can assume that the

00:24:02.510 --> 00:24:08.050
S, that has this optimal property, which is
better in the T I constructed, actually as

00:24:08.050 --> 00:24:14.120
x and y a sibling leaves other maximum depth.
Now, what I am going to do is this S, I am

00:24:14.120 --> 00:24:17.780
going to concretely fuse this and get an S
prime.

00:24:17.780 --> 00:24:23.301
So, this explain will be over k minus 1 letters
except instead of doing this by a recursive

00:24:23.301 --> 00:24:28.620
call, I am actually taking a taking a concrete
tree over k letter and I am actually compressing

00:24:28.620 --> 00:24:34.430
to two nodes into one and call in it to tree
over k minus 1 data set. But, because this

00:24:34.430 --> 00:24:37.700
over k minus 1 letters and these are represent
the encoding, it cannot be any better than

00:24:37.700 --> 00:24:42.860
the encoding that I recursively computed for
k minus 1 letters, because I am assumed by

00:24:42.860 --> 00:24:46.750
induction by that algorithm those efficiently
for k minus 1 letters.

00:24:46.750 --> 00:24:59.760
So, so S prime is no better than T prime,
but S prime plus f of x y is S, T prime plus

00:24:59.760 --> 00:25:05.260
f of x y is T. So, the difference between
T prime and T and S prime S and exactly the

00:25:05.260 --> 00:25:12.660
same. So, the S prime is a then T prime, then
S cannot any better than T. So, it was a contradiction

00:25:12.660 --> 00:25:18.049
to assume that as S was strictly better than
T is this 2Õs that strategy of recursively

00:25:18.049 --> 00:25:21.090
computing T is optimal for all k.

00:25:21.090 --> 00:25:28.570
A word about the implementation, so what we
have to do is k minus 1 time, we have to merge

00:25:28.570 --> 00:25:34.679
this two minimum values and compute the recursive
solution, bottle neck, is finding the minimum

00:25:34.679 --> 00:25:39.840
values. If you use an array, then as we know
scan the array each time to find the minimum

00:25:39.840 --> 00:25:43.420
values, remember that the minimum of values
keep changing, I cannot sort it once in for

00:25:43.420 --> 00:25:47.830
all. Because, each time I combine two letters,
I introduce a new letter into my array with

00:25:47.830 --> 00:25:52.090
a new minimum value which was not there before
and not a new value, which may not there before

00:25:52.090 --> 00:25:56.880
it is may or may not be the minimum.
So, each state I have to find the minimum,

00:25:56.880 --> 00:26:03.120
so it is an order k scan each time, so linear
scan and I do this about k these times. So,

00:26:03.120 --> 00:26:08.860
I get order k square, but it should be fairly
cleared into see that this bottle neck can

00:26:08.860 --> 00:26:13.060
be got around by using a heap, where there
is precise what heaps are good at finding

00:26:13.060 --> 00:26:14.060
the minimum.

00:26:14.060 --> 00:26:19.230
So, if I maintain the frequencies not as a
simple list or array, but as a heap, then

00:26:19.230 --> 00:26:24.460
in order log k time, I can find the minimum
values and then I can insert back the new

00:26:24.460 --> 00:26:28.650
composite letter also into heap in to log
k time. So, each iteration takes some log

00:26:28.650 --> 00:26:34.670
k, and so I improve from k square to k log
k.

00:26:34.670 --> 00:26:39.880
So, recall that, we mentioned in the beginning
that this is going to be a last greedy algorithm.

00:26:39.880 --> 00:26:45.060
So, why is this greedy, well because every
time, we make a recursive call, we are deciding

00:26:45.060 --> 00:26:50.360
to combine two nodes into one and the two
letters we are choose always once with the

00:26:50.360 --> 00:26:54.320
lowest frequencies. Now, what is to say, that
we could not do better by choosing the lowest

00:26:54.320 --> 00:26:59.170
then the third rows per, but we now a try,
we only try to lowest to the second rows.

00:26:59.170 --> 00:27:03.930
So, we make a locally optimal choice and we
keep going with choice, never going back to

00:27:03.930 --> 00:27:08.520
re-visit it, and finally we get a global solution.
Now, we have to prove that this global solution

00:27:08.520 --> 00:27:13.210
is actually optimal and we have to do that,
because there is no other reason is expect

00:27:13.210 --> 00:27:18.290
that by making a short sited choice, at the
current time take the two worst frequencies

00:27:18.290 --> 00:27:22.290
and combine them, that you are always going
to get the best solution. So, this is very

00:27:22.290 --> 00:27:25.370
much a greedy stunt.

00:27:25.370 --> 00:27:31.770
So, finally a brief historical note, so Clot
Shannon is the father of information theory

00:27:31.770 --> 00:27:39.030
and when, we are looking at these problems
around 1950 or, so they were faced with this

00:27:39.030 --> 00:27:43.830
problem are finding an efficient encoding.
So, Shannon and Fano, proposed the divide

00:27:43.830 --> 00:27:47.490
and conquer thing, so what us it was let us
look at the encoding of the alphabet. So,

00:27:47.490 --> 00:27:51.330
some of them are going to start with 0, some
other going to start with 1.

00:27:51.330 --> 00:27:57.679
Everything which is in the left sub tree of
this coding tree that we construct is going

00:27:57.679 --> 00:28:01.419
to have a code of the form 0 something, something,
everything on the right is going to have something

00:28:01.419 --> 00:28:07.170
at the from 1 something, something. So, it
seem intuitive to them, that divide and conquer

00:28:07.170 --> 00:28:12.570
strategy is good, what you can put letters
on this side, such that the occupied roughly

00:28:12.570 --> 00:28:17.540
of the frequency weight of the total alphabet.
That is a frequencies of all the letters,

00:28:17.540 --> 00:28:22.850
who's encoding start with 0, their frequencies
added to roughly half and the other one also

00:28:22.850 --> 00:28:26.260
to half.
So, split the alphabet in the two of equal

00:28:26.260 --> 00:28:30.210
weight assign some of them to start with 0Õs,
the other to start with 1, then I recursive

00:28:30.210 --> 00:28:35.790
it is solve this. So, a partition is A 1,
A 2, sums of the frequencies in each other

00:28:35.790 --> 00:28:42.340
sets are roughly equal, solve them recursively.
Unfortunately, this is not guaranteed to generate

00:28:42.340 --> 00:28:46.830
an optimal encoding, you can come up with
examples, where you can do this and then end

00:28:46.830 --> 00:28:50.080
of the something which you can improve by
doing some other thing.

00:28:50.080 --> 00:28:55.230
So, it turned out the Huffman was a graduates
student in a course of Fano, he heard about

00:28:55.230 --> 00:28:59.990
this problem and we thought about it, and
after a few years he came up with this clever

00:28:59.990 --> 00:29:01.309
algorithm which we have done today.

